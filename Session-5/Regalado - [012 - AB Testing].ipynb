{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace10193",
   "metadata": {},
   "source": [
    "# Challenge lab - AB Testing \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48117083",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "\n",
    "To aid in resource identification later, the random and string libraries were imported and used in a helper function that generates a random string with a length of 10.\n",
    "The output of the helper function was then assigned to the prefix variable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59efc06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from string import ascii_lowercase\n",
    "\n",
    "def generate_random_string(length=10):\n",
    "    letters = ascii_lowercase\n",
    "    return ''.join(choice(letters) for i in range(length))\n",
    "\n",
    "prefix = generate_random_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ec460f",
   "metadata": {},
   "source": [
    "## Import model artifacts\n",
    "\n",
    "To import the model artifacts, I simply specified the S3 path of the model artifacts of the Linear Learner and XGBoost models I created during the 21-day Challenge project that achieved the best results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c994f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = 's3://sagemaker-us-east-1-305262579855/sagemaker/regalado/capstone-model/linear-learner-2021-05-27-12-57-03-537/output/model.tar.gz'\n",
    "model_b = 's3://sagemaker-us-east-1-305262579855/sagemaker/regalado/capstone-model/sagemaker-xgboost-2021-05-29-06-58-19-912/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e46872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "region = boto3.Session().region_name    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39565092",
   "metadata": {},
   "source": [
    "## Retrieve image URIs\n",
    "\n",
    "Since two models will be used, the retrieve method was used to acquire the image URIs of the Linear Learner and XGBoost algorithms and were assigned to their corresponding variables.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99ec939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "image_uri_1 = retrieve('linear-learner', region, version=\"1\")\n",
    "image_uri_2 = retrieve(\"xgboost\", region, version=\"0.90-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e962c6a",
   "metadata": {},
   "source": [
    "## Prepare containers\n",
    "\n",
    "In order to prepare both models for deployment, we first have to specify the containers that we will be using in our inference pipeline. \n",
    "To achieve this, we simply have to fill in the values for the Image, ContainerHostname, and ModelDataUrl attributes below.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3759751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "container1 = { \n",
    "    'Image': image_uri_1,\n",
    "    'ContainerHostname': 'modelA',\n",
    "    'ModelDataUrl': model_a\n",
    "}\n",
    "\n",
    "container2 = { \n",
    "    'Image': image_uri_2,\n",
    "    'ContainerHostname': 'modelB',\n",
    "    'ModelDataUrl': model_b\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2f846",
   "metadata": {},
   "source": [
    "## Init sagemaker_session and other required variables\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd07f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "sm_client = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a93d36",
   "metadata": {},
   "source": [
    "## Set identifiers\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e5c36635",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_a = \"kent-ab-model-a-\" + prefix\n",
    "model_name_b = \"kent-ab-model-b-\" + prefix\n",
    "endpoint_config_name = 'kent-ab-endpoint-config-' + prefix\n",
    "endpoint_name = 'kent-ab-endpoint-' + prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a368f",
   "metadata": {},
   "source": [
    "## Model creation\n",
    "\n",
    "In this code segment, the create_model method was used to create both models in preparation for deployment. \n",
    "Next, the ModelName, ExecutionRoleArn, and the Containers attributes were filled in with the requisite variables and list of Docker containers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "de2e213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_client.create_model(\n",
    "    ModelName        = model_name_a,\n",
    "    ExecutionRoleArn = role,\n",
    "    Containers       = [container1]\n",
    ")\n",
    "\n",
    "response = sm_client.create_model(\n",
    "    ModelName        = model_name_b,\n",
    "    ExecutionRoleArn = role,\n",
    "    Containers       = [container2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7829e879",
   "metadata": {},
   "source": [
    "## Production variant description\n",
    "\n",
    "Since we will be deploying two models for AB Testing, we need to specify a production variant description for both models. \n",
    "This is achieved using the production_variant method.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c237aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import production_variant\n",
    "\n",
    "variant_name_a = prefix + '-variant-A'\n",
    "variant_name_b = prefix + '-variant-B'\n",
    "\n",
    "variant1 = production_variant(\n",
    "    model_name=model_name_a,\n",
    "    instance_type=\"ml.t2.medium\",\n",
    "    initial_instance_count=1,\n",
    "    variant_name=variant_name_a,\n",
    "    initial_weight=0.5\n",
    ")\n",
    "                              \n",
    "variant2 = production_variant(\n",
    "    model_name=model_name_b,\n",
    "    instance_type=\"ml.t2.medium\",\n",
    "    initial_instance_count=1,\n",
    "    variant_name=variant_name_b,\n",
    "    initial_weight=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b18273f",
   "metadata": {},
   "source": [
    "## Model deployment\n",
    "\n",
    "The models are deployed using the endpoint_from_production_variants method which creates a SageMaker endpoint from the list of production variants.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3895c707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kent-ab-endpoint-hfcmmjeflm'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session.endpoint_from_production_variants(\n",
    "    name=endpoint_name,\n",
    "    production_variants=[variant1, variant2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56e07c9",
   "metadata": {},
   "source": [
    "## Invoke SageMaker inference endpoint\n",
    "\n",
    "Before invoking the created inference endpoint, a low-level client representing Amazon SageMaker Runtime must first be instantiated. This is done using the client method from the AWS SDK for Python (boto3)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ff3e9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa9c84",
   "metadata": {},
   "source": [
    "## Prepare input data\n",
    "\n",
    "Since both models are expecting an input data with seven feature columns, I simply copied some values from the synthetic test data from the 21-day Challenge project.\n",
    "Since the invoke_endpoint method below only accepts bytes and bytearray objects, the .encode method was used to convert the string variable to a bytes object and the \n",
    "final result was stored in the sample_body variable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4c0c58c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = '0.5531491564, 1.9234457948, -0.5482002982, -1.1234940332, -0.7746149700, -2.0820987032, 0.2428820132'\n",
    "\n",
    "sample_body = str.encode(temp)\n",
    "type(sample_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ade077",
   "metadata": {},
   "source": [
    "## Invoke inference endpoint \n",
    "\n",
    "To invoke the endpoint, the test_endpoint helper function was used. Inside the helper function, the invoke_endpoint was used to generate the model predictions for both models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55ff3f1",
   "metadata": {},
   "source": [
    "### variant-A: Linear Learner\n",
    "### variant-B: XGBoost\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cfa9fe57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hfcmmjeflm-variant-B -> 97.89613342285156\n",
      "hfcmmjeflm-variant-B -> 97.89613342285156\n",
      "hfcmmjeflm-variant-B -> 97.89613342285156\n",
      "hfcmmjeflm-variant-B -> 97.89613342285156\n",
      "hfcmmjeflm-variant-B -> 97.89613342285156\n",
      "hfcmmjeflm-variant-A -> {\"predictions\": [{\"score\": -145.47348022460938}]}\n",
      "hfcmmjeflm-variant-A -> {\"predictions\": [{\"score\": -145.47348022460938}]}\n",
      "hfcmmjeflm-variant-A -> {\"predictions\": [{\"score\": -145.47348022460938}]}\n",
      "hfcmmjeflm-variant-B -> 97.89613342285156\n",
      "hfcmmjeflm-variant-A -> {\"predictions\": [{\"score\": -145.47348022460938}]}\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "def test_endpoint(runtime_client, endpoint_name, body):\n",
    "    response = runtime_client.invoke_endpoint(\n",
    "        EndpointName = endpoint_name,\n",
    "        ContentType  = 'text/csv',\n",
    "        Body         = body\n",
    "    )\n",
    "    \n",
    "    variant = response['InvokedProductionVariant']\n",
    "    prediction = response['Body'].read().decode(\"utf-8\")\n",
    "\n",
    "    print(variant + \" -> \"+ prediction)\n",
    "    sleep(2)\n",
    "\n",
    "for _ in range(0, 10):\n",
    "    test_endpoint(runtime_client, endpoint_name, sample_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231af2c3",
   "metadata": {},
   "source": [
    "---\n",
    "### target value = 114.7073731291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6cca19c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hfcmmjeflm-variant-B -> 97.89613342285156\n",
      "hfcmmjeflm-variant-B -> 97.89613342285156\n",
      "hfcmmjeflm-variant-B -> 97.89613342285156\n",
      "hfcmmjeflm-variant-B -> 97.89613342285156\n",
      "hfcmmjeflm-variant-B -> 97.89613342285156\n"
     ]
    }
   ],
   "source": [
    "def test_endpoint_2(runtime_client, endpoint_name, body, variant_name):\n",
    "    response = runtime_client.invoke_endpoint(\n",
    "        EndpointName = endpoint_name,\n",
    "        ContentType  = 'text/csv',\n",
    "        TargetVariant=variant_name,\n",
    "        Body         = body\n",
    "    )\n",
    "    \n",
    "    variant = response['InvokedProductionVariant']\n",
    "    prediction = response['Body'].read().decode(\"utf-8\")\n",
    "\n",
    "    print(variant + \" -> \"+ prediction)\n",
    "    sleep(2)\n",
    "\n",
    "for _ in range(0, 5):\n",
    "    test_endpoint_2(\n",
    "        runtime_client=runtime_client, \n",
    "        endpoint_name=endpoint_name, \n",
    "        body=sample_body, \n",
    "        variant_name=variant_name_b\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1781078",
   "metadata": {},
   "source": [
    "## Delete inference endpoint once done to avoid incurring cost\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "75b07ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted kent-ab-endpoint-hfcmmjeflm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'a5990219-e80c-4b5a-bde2-910e27987523',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a5990219-e80c-4b5a-bde2-910e27987523',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Sat, 05 Jun 2021 05:36:42 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "print(f'Deleted {endpoint_name}')\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
